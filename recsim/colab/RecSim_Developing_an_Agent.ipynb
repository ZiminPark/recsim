{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecSim: Developing an Agent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZiminPark/recsim/blob/master/recsim/colab/RecSim_Developing_an_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtBSsFuoaaNv"
      },
      "source": [
        "# Developing an Agent\n",
        "\n",
        "마지막 퍼즐 Agent 개발로 넘어가 보자. 이번 튜토리얼에서 두 가지를 다룰 것이다.\n",
        "\n",
        "* basics : RecSim에서 어떤 데이터가 agent에 들어가는지, 어떤 걸 return 받기 원하는지\n",
        "\n",
        "* design: 어떤 피쳐가 RecSim에서 agents를 개발하는데 필요한지."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVQshsAMdYai"
      },
      "source": [
        "# Basics\n",
        "\n",
        "\n",
        "<p align=\"center\"><img width=\"50%\" src=\"https://github.com/google-research/recsim/blob/master/recsim/colab/figures/recsim_architecture_agent_centered.png?raw=true\" /></p>\n",
        "\n",
        "Agent는 다음을 consume해야 한다.\n",
        "\n",
        "* 유저 state에 대한 observations\n",
        "* 추천에 대한 유저의 반응 observations\n",
        "* 가능한 documents와 documents 피쳐 벡터.\n",
        "\n",
        "return으로 agent는 $K$개의 추천을 만들고 user's choice와 transition model에 넘겨준다.\n",
        "\n",
        "RecSim's agent API를 설명하기 위해 simple bandit agent for RecSim's *interest exploration* environment을 사용해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1drgXe9CRqH"
      },
      "source": [
        "*interest exploration*은 clustered bandit problem을 말한다. 세상은 topics로 cluster될 수 있는 documents로 구성되어 있고 유저도 cluster될 수 있다고 가정한다.\n",
        "\n",
        "유저의 document에 대한 affinity는 document의 퀄리티 + 유저의 주제에 대한 affinity다.\n",
        "\n",
        "이런 상황은 클릭율이 높은 documents를 높은 순위로 책정하여 근시안적인 정책을 만들어낸다. 이는 suboptimal policy도 수렴하게 되기 때문에 active exploration이 필요하다.\n",
        "\n",
        "method를 각각 나눠보고 나중에 합치자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BHEmh8BUhR_",
        "outputId": "0ba0a895-5630-496e-813b-037338a1f529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install --upgrade --no-cache-dir recsim"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting recsim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/5a/bbd19e986fd3448de90a2808010ddec29d048cff21cd940401c14c8666d6/recsim-0.2.4.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from recsim) (0.10.0)\n",
            "Collecting dopamine-rl>=2.0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a8/443668d6c1a23b6e1713794674296854349c710079d8d4abaedf5623f8cb/dopamine_rl-3.1.8-py3-none-any.whl (117kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gin-config in /usr/local/lib/python3.6/dist-packages (from recsim) (0.3.0)\n",
            "Requirement already satisfied, skipping upgrade: gym in /usr/local/lib/python3.6/dist-packages (from recsim) (0.17.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from recsim) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from recsim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow in /usr/local/lib/python3.6/dist-packages (from recsim) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from absl-py->recsim) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: jaxlib>=0.1.51 in /usr/local/lib/python3.6/dist-packages (from dopamine-rl>=2.0.5->recsim) (0.1.56+cuda101)\n",
            "Collecting flax>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/ef/1a0c6a869396e4b20a83375fe06d725b5c1711746578ee8dd6969472af41/flax-0.2.2-py3-none-any.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 42.6MB/s \n",
            "\u001b[?25hCollecting tf-slim>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 48.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from dopamine-rl>=2.0.5->recsim) (1.1.4)\n",
            "Requirement already satisfied, skipping upgrade: jax>=0.1.72 in /usr/local/lib/python3.6/dist-packages (from dopamine-rl>=2.0.5->recsim) (0.2.4)\n",
            "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from dopamine-rl>=2.0.5->recsim) (7.0.0)\n",
            "Collecting pygame>=1.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/4c/2ebe8ab1a695a446574bc48d96eb3503649893be8c769e7fafd65fd18833/pygame-2.0.0-cp36-cp36m-manylinux1_x86_64.whl (11.5MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5MB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: opencv-python>=3.4.8.29 in /usr/local/lib/python3.6/dist-packages (from dopamine-rl>=2.0.5->recsim) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->recsim) (1.5.0)\n",
            "Requirement already satisfied, skipping upgrade: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->recsim) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (1.33.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (0.35.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->recsim) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from flax>=0.2.0->dopamine-rl>=2.0.5->recsim) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: msgpack in /usr/local/lib/python3.6/dist-packages (from flax>=0.2.0->dopamine-rl>=2.0.5->recsim) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from flax>=0.2.0->dopamine-rl>=2.0.5->recsim) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->dopamine-rl>=2.0.5->recsim) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->dopamine-rl>=2.0.5->recsim) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->recsim) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow->recsim) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->recsim) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->recsim) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->recsim) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->recsim) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->recsim) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->recsim) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax>=0.2.0->dopamine-rl>=2.0.5->recsim) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax>=0.2.0->dopamine-rl>=2.0.5->recsim) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax>=0.2.0->dopamine-rl>=2.0.5->recsim) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->recsim) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->recsim) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->recsim) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->recsim) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->recsim) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->recsim) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->recsim) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->recsim) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->recsim) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->recsim) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->recsim) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->recsim) (3.1.0)\n",
            "Building wheels for collected packages: recsim\n",
            "  Building wheel for recsim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for recsim: filename=recsim-0.2.4-cp36-none-any.whl size=105530 sha256=01b4cc4c069bc6896331f987a40ce31f9259c5cf9a342fda6fc31119b2150b6b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mmx7t2ch/wheels/3f/a8/d9/d208990c5e1b61069e68c1f8a3cec81254635d412b83de460f\n",
            "Successfully built recsim\n",
            "Installing collected packages: flax, tf-slim, pygame, dopamine-rl, recsim\n",
            "  Found existing installation: dopamine-rl 1.0.5\n",
            "    Uninstalling dopamine-rl-1.0.5:\n",
            "      Successfully uninstalled dopamine-rl-1.0.5\n",
            "Successfully installed dopamine-rl-3.1.8 flax-0.2.2 pygame-2.0.0 recsim-0.2.4 tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlMUGf8CdX6D"
      },
      "source": [
        "import functools\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from recsim import agent\n",
        "from recsim import document\n",
        "from recsim import user\n",
        "from recsim.choice_model import MultinomialLogitChoiceModel\n",
        "from recsim.simulator import environment\n",
        "from recsim.simulator import recsim_gym\n",
        "from recsim.simulator import runner_lib\n",
        "from recsim.environments import interest_exploration"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tismgekhub0Z"
      },
      "source": [
        "env는 관심사가 아니기 때문에 주어지는 걸 사용하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Z9GmFDEYjD"
      },
      "source": [
        "env_config = {'slate_size': 2,\n",
        "              'seed': 0,\n",
        "              'num_candidates': 15,\n",
        "              'resample_documents': True}\n",
        "ie_environment = interest_exploration.create_environment(env_config)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weXPwsYAFV6W"
      },
      "source": [
        "initial_observation = ie_environment.reset()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSDtDdzSF45O"
      },
      "source": [
        "## Observations\n",
        "\n",
        "RecSim의 observation은 dict이고 key가 3가지 있다:\n",
        "* 'user', 위 그림에서 'User Observable Features'를 나타낸다.\n",
        "* 'doc', 추천할 수 있는 Document와 그 피쳐('Document Observable Features'),\n",
        "* 'response', 마지막 추천에 대한 유저의 반응('User Response'). \n",
        "\n",
        "이번 environment에서는 유저의 observable features를 구현하지 않았다. 그래서 이 필드는 계속 empty이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRJd0MWaGale",
        "outputId": "32d475a5-b5d4-47de-b3c7-f967668dfee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('User Observable Features')\n",
        "print(initial_observation['user'])\n",
        "print('User Response')\n",
        "print(initial_observation['response'])\n",
        "print('Document Observable Features')\n",
        "for doc_id, doc_features in initial_observation['doc'].items():\n",
        "  print('ID:', doc_id, 'features:', doc_features)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User Observable Features\n",
            "[]\n",
            "User Response\n",
            "None\n",
            "Document Observable Features\n",
            "ID: 15 features: {'quality': array(1.22720163), 'cluster_id': 1}\n",
            "ID: 16 features: {'quality': array(1.29258489), 'cluster_id': 1}\n",
            "ID: 17 features: {'quality': array(1.23977078), 'cluster_id': 1}\n",
            "ID: 18 features: {'quality': array(1.46045555), 'cluster_id': 1}\n",
            "ID: 19 features: {'quality': array(2.10233425), 'cluster_id': 0}\n",
            "ID: 20 features: {'quality': array(1.09572905), 'cluster_id': 1}\n",
            "ID: 21 features: {'quality': array(2.37256963), 'cluster_id': 0}\n",
            "ID: 22 features: {'quality': array(1.34928002), 'cluster_id': 1}\n",
            "ID: 23 features: {'quality': array(1.00670188), 'cluster_id': 1}\n",
            "ID: 24 features: {'quality': array(1.20448562), 'cluster_id': 1}\n",
            "ID: 25 features: {'quality': array(2.18351159), 'cluster_id': 0}\n",
            "ID: 26 features: {'quality': array(1.19411585), 'cluster_id': 1}\n",
            "ID: 27 features: {'quality': array(1.03514646), 'cluster_id': 1}\n",
            "ID: 28 features: {'quality': array(2.29592623), 'cluster_id': 0}\n",
            "ID: 29 features: {'quality': array(2.05936556), 'cluster_id': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOvbXmVQF371",
        "outputId": "8975e6bd-533f-4b70-d506-05473199eb59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Document observation space')\n",
        "for key, space in ie_environment.observation_space['doc'].spaces.items():\n",
        "  print(key, ':', space)\n",
        "print('Response observation space')\n",
        "print(ie_environment.observation_space['response'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Document observation space\n",
            "15 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "16 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "17 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "18 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "19 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "20 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "21 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "22 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "23 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "24 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "25 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "26 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "27 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "28 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "29 : Dict(cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32))\n",
            "Response observation space\n",
            "Tuple(Dict(click:Discrete(2), cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32)), Dict(click:Discrete(2), cluster_id:Discrete(2), quality:Box(0.0, inf, (), float32)))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St4Kr6vYbmCb"
      },
      "source": [
        "## Slates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GARdpz7tEN83",
        "outputId": "44b49d95-5c1b-4e1a-bb45-39b75fe0054d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "slate = [0, 1]\n",
        "for slate_doc in slate:\n",
        "  print(list(initial_observation['doc'].items())[slate_doc])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('15', {'quality': array(1.22720163), 'cluster_id': 1})\n",
            "('16', {'quality': array(1.29258489), 'cluster_id': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_k6EaxpdOSE",
        "outputId": "2adbbb31-3c39-42b6-a70b-169ad6e8c592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ie_environment.action_space"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiDiscrete([15 15])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFbqcvKCiIdY"
      },
      "source": [
        "첫 번째 slate가 주어지면 simulator은 env에서 step하고 새로운 observation과 reward를 만든다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5htT89RiGdO"
      },
      "source": [
        "observation, reward, done, _ = ie_environment.step(slate)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd5q0q2qdeX5"
      },
      "source": [
        "The main job of the agent is to produce a valid slate for each step of the simulation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K011d6qbee6J"
      },
      "source": [
        "## A trivial agent\n",
        "\n",
        "- 기본적인 수준에서 agent는 step-function만 구현하는 것으로도 충분하다.\n",
        "- 일단 첫 K개를 추천하는 agent를 만들어보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdAGgbcped1J"
      },
      "source": [
        "from recsim.agent import AbstractEpisodicRecommenderAgent"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbSIEw1ngq0L"
      },
      "source": [
        "- RecSim agent는 *AbstractEpisodicRecommenderAgent*를 상속 받는다. \n",
        "\n",
        "- observation_space 와 action_space가 init에 필요하다. \n",
        "\n",
        "- 이것들을 이용하여 environment가 agent 운영의 전제조건을 충족하는지 검증할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4g5xIwxdb4Z"
      },
      "source": [
        "class StaticAgent(AbstractEpisodicRecommenderAgent):\n",
        "  def __init__(self, observation_space, action_space):\n",
        "    # Check if document corpus is large enough.\n",
        "    if len(observation_space['doc'].spaces) < len(action_space.nvec):\n",
        "      raise RuntimeError('Slate size larger than size of the corpus.')\n",
        "    super(StaticAgent, self).__init__(action_space)\n",
        "\n",
        "  def step(self, reward, observation):\n",
        "    print(observation)\n",
        "    return list(range(self._slate_size))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSCkNfBlsI0E"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKV4mRcgiorx",
        "outputId": "d302dbd6-c1ec-49fe-c336-f32747f1003a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def create_agent(sess, environment, eval_mode, summary_writer=None):\n",
        "  return StaticAgent(environment.observation_space, environment.action_space)\n",
        "\n",
        "tmp_base_dir = '/tmp/recsim/'\n",
        "\n",
        "runner = runner_lib.EvalRunner(\n",
        "  base_dir=tmp_base_dir,\n",
        "  create_agent_fn=create_agent,\n",
        "  env=ie_environment,\n",
        "  max_eval_episodes=1,\n",
        "  max_steps_per_episode=5,\n",
        "  test_mode=True)\n",
        "\n",
        "# We won't run this, but we totally could\n",
        "# runner.run_experiment()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:max_eval_episodes = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:max_eval_episodes = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:max_steps_per_episode = 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:max_steps_per_episode = 5\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jae7rcS8nG5S"
      },
      "source": [
        "# Design: Hierarchical Agent Layers \n",
        "\n",
        "- basic을 만들었으니 좀 더 어려운 것에 도전하고 싶다. \n",
        "\n",
        "- bandit algorithm을 돌려볼 수 있겠다. 유저의 intent가 observable하다고 가정하고 policy을 만들어보자.\n",
        "\n",
        "- 전처리, 추천, 후처리 등 hierarchical한 추천시스템 구조를 설명하는 거 같은데 음... 어떤 맥락에서 이런 이야기가 나왔는지는 원문을 다시보자.\n",
        "\n",
        "The way this problem is set up, a natural heuristic presents itself. We can run a bandit algorithm to reveal the average engagement of a user with each cluster of documents. That is, each cluster becomes an arm. Once the algorithm has chosen a cluster, we serve take the highest quality video from that cluster. This is a metaphor for a situation that occurs often in recommender systems that serve as a front end to multiple (sub-)products: within each session, the user will interact with the recommender with some intent in mind, that is, to realize some task that can be fulfilled by one of the possible sub-products. Sometimes, the user will issue an explicit query (e.g., enter search terms), which effectively makes that intent observable up ot query interpretation uncertainty. Most often, however, the intent will be latent -- the user will reveal it indirectly by chosing among a set of items from the slate. We assume that had the intent been observable, a product-specific policy would be available to fulfill it.\n",
        "\n",
        "This set-up captures some typical features of practical recommender systems -- they tend to very hierarchical, often very heuristic due to the complexity of the environment they operate in, and also very idiosyncratic to the task at hand. For this reason, RecSim's approach to agent engineering is very modular. Instead of providing a wide array of agents, we provide an easily extendable set of agent building blocks, called Agent Layers, which could be combined into hierarchies to create more complex agents.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8mhcm9jEHKv"
      },
      "source": [
        "## Hierarchical agent layers\n",
        "\n",
        "<p align=\"center\"><img width=\"50%\" src=\"https://github.com/google-research/recsim/blob/master/recsim/colab/figures/agent_architecture.png?raw=true\" /></p>\n",
        "\n",
        "hierarchical agent 구조는 대략 다음과 같다:\n",
        "* observation와 reward를 환경으로부터 전처리해서 받고 하나이상의 base agents에 넘겨준다.\n",
        "\n",
        "* 각각의 base agent는 slate나 abstract action을 아웃풋으로 낸 다음, 각각의 레이어에서 후처리하여 구체적인 slate(concrete action)을 만든다.\n",
        "\n",
        "* 각각의 layer는 keras처럼 연결되어서 수정하기 용이하다.\n",
        "\n",
        "요기서는 이런 레이어들을 구체적으로 어떻게 구현할지 설명하지 않을 것이다.(*layers/* directory) 보시라. 대신 용법이나 장점을 살펴보자.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB4VQFzjqKAq"
      },
      "source": [
        "## ClusterClickStats\n",
        "\n",
        "*Interest Exploration*은 clicks을 feedback으로하지만 누적 클릭 수나 impression 횟수는 제공하지 않는다. 그런 통계값을 유지하는 건 유용하기 때문에 agent layer에게 제공할 것이다.(? 이 의미 맞는지 모르겠음)\n",
        "이를 위한 선제조건은 response space가 click과 cluster_id를 key로 갖어야한다. 이런 조건이 맞으면 layer가 어떤 환경/ agent에서도 쓰일 수 있다. 어떻게 쓰이는지 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmKdauxrEGzY"
      },
      "source": [
        "from recsim.agents.layers.cluster_click_statistics import ClusterClickStatsLayer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2lvoE93ma8g"
      },
      "source": [
        "hierarchical agent는 보통 agent와 비슷하게 instantiate된다. cluster click stats의 경우 abstract action을 아무 후처리하지 않는다.\n",
        "\n",
        "cluster click stats에 충분한 통계치를 base agent의 observation space에 clicks과 impressions 값을 inject한다.\n",
        "따라서 둘의 조합은 base agent가 observation space의 추가적인 field처럼 작동한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EMysDE43nn8",
        "outputId": "7736d879-74d7-4b39-a530-807f0a88eac9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "static_agent = StaticAgent(ie_environment.observation_space,\n",
        "                           ie_environment.action_space)\n",
        "static_agent.step(reward, observation)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'user': array([], dtype=float64), 'doc': OrderedDict([('30', {'quality': array(2.48922445), 'cluster_id': 0}), ('31', {'quality': array(2.12592661), 'cluster_id': 0}), ('32', {'quality': array(1.27448139), 'cluster_id': 1}), ('33', {'quality': array(1.21799112), 'cluster_id': 1}), ('34', {'quality': array(1.17770375), 'cluster_id': 1}), ('35', {'quality': array(2.07948915), 'cluster_id': 0}), ('36', {'quality': array(1.14167652), 'cluster_id': 1}), ('37', {'quality': array(1.20529165), 'cluster_id': 1}), ('38', {'quality': array(1.2424684), 'cluster_id': 1}), ('39', {'quality': array(1.87279668), 'cluster_id': 0}), ('40', {'quality': array(1.19644888), 'cluster_id': 1}), ('41', {'quality': array(1.28254021), 'cluster_id': 1}), ('42', {'quality': array(2.01558539), 'cluster_id': 0}), ('43', {'quality': array(2.46400483), 'cluster_id': 0}), ('44', {'quality': array(1.33980633), 'cluster_id': 1})]), 'response': ({'click': 0, 'quality': array(1.22720163), 'cluster_id': 1}, {'click': 0, 'quality': array(1.29258489), 'cluster_id': 1})}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H7wzqfD27Em",
        "outputId": "539cac9e-94eb-44c3-9424-19648805fd3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cluster_static_agent = ClusterClickStatsLayer(StaticAgent,\n",
        "                                              ie_environment.observation_space,\n",
        "                                              ie_environment.action_space)\n",
        "cluster_static_agent.step(reward, observation)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'user': {'raw_observation': array([], dtype=float64), 'sufficient_statistics': {'impression_count': array([0, 2]), 'click_count': array([0, 0])}}, 'doc': OrderedDict([('30', {'quality': array(2.48922445), 'cluster_id': 0}), ('31', {'quality': array(2.12592661), 'cluster_id': 0}), ('32', {'quality': array(1.27448139), 'cluster_id': 1}), ('33', {'quality': array(1.21799112), 'cluster_id': 1}), ('34', {'quality': array(1.17770375), 'cluster_id': 1}), ('35', {'quality': array(2.07948915), 'cluster_id': 0}), ('36', {'quality': array(1.14167652), 'cluster_id': 1}), ('37', {'quality': array(1.20529165), 'cluster_id': 1}), ('38', {'quality': array(1.2424684), 'cluster_id': 1}), ('39', {'quality': array(1.87279668), 'cluster_id': 0}), ('40', {'quality': array(1.19644888), 'cluster_id': 1}), ('41', {'quality': array(1.28254021), 'cluster_id': 1}), ('42', {'quality': array(2.01558539), 'cluster_id': 0}), ('43', {'quality': array(2.46400483), 'cluster_id': 0}), ('44', {'quality': array(1.33980633), 'cluster_id': 1})]), 'response': ({'click': 0, 'quality': array(1.22720163), 'cluster_id': 1}, {'click': 0, 'quality': array(1.29258489), 'cluster_id': 1})}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeyrpnNI3onL"
      },
      "source": [
        "'user' field가 변한 것을 볼 수 있다. `sufficient_statistics`가 새로운 key로 생겼고 old user observation은 `raw_observation`으로 갔다. 네이밍 충돌을 막기위해 이렇게 했다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6FSXE_eqCMP"
      },
      "source": [
        "## AbstractClickBandit\n",
        "\n",
        "`ClusterClickStats`은 exploration을 위한 statistics을 갖고 있음을 보았다. 실제 `bandit policy`를 구현하기 위해 RecSim은 `AbstractClickBandit`을 제공한다. \n",
        "\n",
        "\n",
        "`AbstractClickBandit`는 base agents의 list를 받고 각각을 arms로 취급한다. 그리고 몇몇 bandit policies (UCB1, KL-UCB, ThompsonSampling)을 구현하여 best policy에 대한 sub-linear regret을 달성한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0vDml6hqXSS"
      },
      "source": [
        "from recsim.agents.layers.abstract_click_bandit import AbstractClickBanditLayer"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYA94M_puOs1"
      },
      "source": [
        "`abstract bandit`을 만드려면 list of base agents를 줘야한다. 우리의 경우, 클러스터마다 한 개의 base agent를 갖는다. 각 클러스터에서 retrieves하여 perceived quality에 따라 정렬한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRRAhUTtun-S"
      },
      "source": [
        "class GreedyClusterAgent(agent.AbstractEpisodicRecommenderAgent):\n",
        "  \"\"\"Simple agent sorting all documents of a topic according to quality.\"\"\"\n",
        "\n",
        "  def __init__(self, observation_space, action_space, cluster_id, **kwargs):\n",
        "    del observation_space\n",
        "    super(GreedyClusterAgent, self).__init__(action_space)\n",
        "    self._cluster_id = cluster_id\n",
        "\n",
        "  def step(self, reward, observation):\n",
        "    del reward\n",
        "    my_docs = []\n",
        "    my_doc_quality = []\n",
        "    for i, doc in enumerate(observation['doc'].values()):\n",
        "      if doc['cluster_id'] == self._cluster_id:\n",
        "        my_docs.append(i)\n",
        "        my_doc_quality.append(doc['quality'])\n",
        "    if not bool(my_docs):\n",
        "      return []\n",
        "    sorted_indices = np.argsort(my_doc_quality)[::-1]\n",
        "    return list(np.array(my_docs)[sorted_indices])\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph9XmH_1usdR"
      },
      "source": [
        "We will now instantiate one GreedyClusterAgent for each cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ7DO1yqus_f"
      },
      "source": [
        "  num_topics = list(ie_environment.observation_space.spaces['doc']\n",
        "                    .spaces.values())[0].spaces['cluster_id'].n\n",
        "  base_agent_ctors = [\n",
        "      functools.partial(GreedyClusterAgent, cluster_id=i)\n",
        "      for i in range(num_topics)\n",
        "  ]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lld6Y3KZvWVy"
      },
      "source": [
        "We can now instantiate our cluster bandit as a combination of ClusterClickStats, AbstractClickBandit, and GreedyClusterAgent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrgbdGUSvVcj"
      },
      "source": [
        "bandit_ctor = functools.partial(AbstractClickBanditLayer,\n",
        "                                arm_base_agent_ctors=base_agent_ctors)\n",
        "cluster_bandit = ClusterClickStatsLayer(bandit_ctor,\n",
        "                                        ie_environment.observation_space,\n",
        "                                        ie_environment.action_space)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_HoVSVhww-n"
      },
      "source": [
        "Our ClusterBandit is ready to use!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LVPU3ukw06u",
        "outputId": "2bae92af-e2f1-4d1e-e39b-a53e3f18a171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "observation0 = ie_environment.reset()\n",
        "slate = cluster_bandit.begin_episode(observation0)\n",
        "print(\"Cluster bandit slate 0:\")\n",
        "doc_list = list(observation0['doc'].values())\n",
        "for doc_position in slate:\n",
        "  print(doc_list[doc_position])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster bandit slate 0:\n",
            "{'quality': array(2.36424144), 'cluster_id': 0}\n",
            "{'quality': array(2.30721859), 'cluster_id': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}